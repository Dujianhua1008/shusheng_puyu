欢迎大家参与[大模型实训营](https://github.com/InternLM/Tutorial)


# 项目背景
注意到社区的项目以应用为主，个人对于模型量化算子开发很感兴趣，因此此项目计划以此平台为基础，开发量化算法库，为对模型量化具有同样兴趣的朋友提供参考。
![image](https://github.com/user-attachments/assets/23800749-3861-4deb-8211-2a5a86739314)


# 项目功能
LLM 自动量化库
为LLM模型提供4bit量化，初步计划使用AWQ GPTQ。

# 关键技术点
量化函数

量化层的实现和替换

低比特打包和解包推理

算子融合

# 致谢
模型基于InternLM实现。感谢上海人工智能实验室推出的书生·浦语大模型实战营，为我们的项目提供宝贵的技术指导和强大的算力支持。
